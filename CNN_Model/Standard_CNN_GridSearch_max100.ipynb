{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of attempt2_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1KxVHO34RQF8-qOqoD0BPZsYKlhTNRIkw",
      "authorship_tag": "ABX9TyMP7mXSd902ULeKALxio9Vc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krystaldowling/MAST30034_Final_Project-/blob/CNN_Model/Standard_CNN_GridSearch_max100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1-HosE7V5wu"
      },
      "source": [
        "This document contains code modified from https://realpython.com/python-keras-text-classification/. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trD-9g79UzrQ"
      },
      "source": [
        "# Import statements\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKqPoZiXboFq",
        "outputId": "d7ddb520-d5e2-4f85-8a3b-69b07b8d726e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "# Loading in preproccessed data\n",
        "PATH = \"/content/drive/My Drive/Data/\"\n",
        "data = pd.read_csv(PATH + \"preproccessed_data.csv\", lineterminator='\\n')\n",
        "\n",
        "data"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>muslims busted stole millions gov ’ benefits</td>\n",
              "      <td>print pay back money plus interest entire fami...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>attorney general loretta lynch plead fifth</td>\n",
              "      <td>attorney general loretta lynch plead fifth bar...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>breaking weiner cooperating fbi hillary email ...</td>\n",
              "      <td>red state fox news sunday reported morning ant...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pin drop speech father daughter kidnapped kill...</td>\n",
              "      <td>email kayla mueller prisoner tortured isis cha...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fantastic trumps 7 point plan reform healthcar...</td>\n",
              "      <td>email healthcare reform make america great sin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29449</th>\n",
              "      <td>process analytical instruments market – techna...</td>\n",
              "      <td>technavio published new report global process ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29450</th>\n",
              "      <td>travel deals get 1200 air credit two apt cookt...</td>\n",
              "      <td>apt offering savings new cape york outback wil...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29451</th>\n",
              "      <td>taiwanese recyclers belief waste simply mispla...</td>\n",
              "      <td>taipei taiwan sept 8 2015 prnewswire recent ye...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29452</th>\n",
              "      <td>season curtain raiser ideal way honour john</td>\n",
              "      <td>blackburn sunday league john haydock memorial ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29453</th>\n",
              "      <td>four cooper standard facilities promote north ...</td>\n",
              "      <td>novi mich sept 30 2015 prnewswire four cooper ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29454 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   title  ... label\n",
              "0           muslims busted stole millions gov ’ benefits  ...     1\n",
              "1             attorney general loretta lynch plead fifth  ...     1\n",
              "2      breaking weiner cooperating fbi hillary email ...  ...     1\n",
              "3      pin drop speech father daughter kidnapped kill...  ...     1\n",
              "4      fantastic trumps 7 point plan reform healthcar...  ...     1\n",
              "...                                                  ...  ...   ...\n",
              "29449  process analytical instruments market – techna...  ...     0\n",
              "29450  travel deals get 1200 air credit two apt cookt...  ...     0\n",
              "29451  taiwanese recyclers belief waste simply mispla...  ...     0\n",
              "29452        season curtain raiser ideal way honour john  ...     0\n",
              "29453  four cooper standard facilities promote north ...  ...     0\n",
              "\n",
              "[29454 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36438kdFcw4S"
      },
      "source": [
        "# Performing test-train split\n",
        "text_train, text_test, y_train, y_test = train_test_split(data['text'].values, data['label'].values, test_size=0.25, random_state=1000)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQYfsMDoc_LD"
      },
      "source": [
        "# Tokenizing data\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(text_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(text_train)\n",
        "X_test = tokenizer.texts_to_sequences(text_test)\n",
        "\n",
        "# Vocab size- adding 1 because of reserved 0 index\n",
        "vocab_size = len(tokenizer.word_index) + 1  "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EDjazuKdi1R"
      },
      "source": [
        "# Padding sequences\n",
        "maxlen = 100\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaMXS3QdCinA"
      },
      "source": [
        "# Create Model\n",
        "def create_model(num_filters, kernel_size, vocab_size, embedding_dim, maxlen):\n",
        "    model = Sequential()\n",
        "    model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
        "    model.add(layers.Conv1D(num_filters, kernel_size, activation='relu'))\n",
        "    model.add(layers.GlobalMaxPooling1D())\n",
        "    model.add(layers.Dense(6, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzvfInxSo0r2"
      },
      "source": [
        "# Defining possible parameters \n",
        "param_grid = dict(num_filters=[32, 64, 128],\n",
        "                  kernel_size=[3, 5, 7],\n",
        "                  vocab_size= [vocab_size], \n",
        "                  embedding_dim=[100],\n",
        "                  maxlen= [100])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o42bxuT7fUrB",
        "outputId": "9882321d-ad31-4f31-e91d-eb4affb3a129",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Run grid search on data\n",
        "model = KerasClassifier(build_fn=create_model, epochs=6, batch_size=16)\n",
        "grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid, cv=4, verbose=1, n_iter=4)\n",
        "# Fitting Model\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate testing set\n",
        "test_accuracy = grid.score(X_test, y_test)\n",
        "print(test_accuracy)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 188s 182ms/step - loss: 0.4543 - accuracy: 0.7848\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 188s 182ms/step - loss: 0.2716 - accuracy: 0.8980\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 188s 182ms/step - loss: 0.1158 - accuracy: 0.9652\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 188s 181ms/step - loss: 0.0422 - accuracy: 0.9896\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 188s 182ms/step - loss: 0.0222 - accuracy: 0.9948\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 188s 181ms/step - loss: 0.0125 - accuracy: 0.9971\n",
            "346/346 [==============================] - 1s 2ms/step - loss: 0.7822 - accuracy: 0.8289\n",
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 188s 182ms/step - loss: 0.4419 - accuracy: 0.7940\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 188s 181ms/step - loss: 0.2602 - accuracy: 0.9058\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 188s 181ms/step - loss: 0.1279 - accuracy: 0.9587\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 188s 181ms/step - loss: 0.0522 - accuracy: 0.9856\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 188s 181ms/step - loss: 0.0229 - accuracy: 0.9943\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 187s 180ms/step - loss: 0.0134 - accuracy: 0.9967\n",
            "346/346 [==============================] - 1s 2ms/step - loss: 0.7289 - accuracy: 0.8300\n",
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 186s 180ms/step - loss: 0.4520 - accuracy: 0.7865\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 186s 180ms/step - loss: 0.2628 - accuracy: 0.9014\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 186s 180ms/step - loss: 0.1039 - accuracy: 0.9681\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 186s 179ms/step - loss: 0.0356 - accuracy: 0.9919\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 185s 179ms/step - loss: 0.0197 - accuracy: 0.9949\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 186s 179ms/step - loss: 0.0111 - accuracy: 0.9964\n",
            "346/346 [==============================] - 1s 2ms/step - loss: 0.6899 - accuracy: 0.8261\n",
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 185s 179ms/step - loss: 0.4697 - accuracy: 0.7837\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 186s 179ms/step - loss: 0.2830 - accuracy: 0.8962\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 186s 179ms/step - loss: 0.1495 - accuracy: 0.9568\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 186s 179ms/step - loss: 0.0862 - accuracy: 0.9789\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 185s 179ms/step - loss: 0.0593 - accuracy: 0.9861\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 184s 178ms/step - loss: 0.0395 - accuracy: 0.9911\n",
            "346/346 [==============================] - 1s 2ms/step - loss: 0.6408 - accuracy: 0.8180\n",
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 185s 179ms/step - loss: 0.4533 - accuracy: 0.7939\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 185s 179ms/step - loss: 0.2785 - accuracy: 0.8962\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 185s 179ms/step - loss: 0.1465 - accuracy: 0.9542\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 185s 179ms/step - loss: 0.0725 - accuracy: 0.9789\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 185s 179ms/step - loss: 0.0360 - accuracy: 0.9919\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 184s 178ms/step - loss: 0.0312 - accuracy: 0.9937\n",
            "346/346 [==============================] - 1s 2ms/step - loss: 0.6251 - accuracy: 0.8287\n",
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 185s 178ms/step - loss: 0.4518 - accuracy: 0.7919\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 185s 179ms/step - loss: 0.2694 - accuracy: 0.8999\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 185s 179ms/step - loss: 0.1264 - accuracy: 0.9619\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 185s 179ms/step - loss: 0.0565 - accuracy: 0.9862\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 185s 179ms/step - loss: 0.0403 - accuracy: 0.9918\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 186s 179ms/step - loss: 0.0264 - accuracy: 0.9947\n",
            "346/346 [==============================] - 1s 2ms/step - loss: 0.6560 - accuracy: 0.8182\n",
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 186s 179ms/step - loss: 0.4530 - accuracy: 0.7886\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 186s 180ms/step - loss: 0.2644 - accuracy: 0.9011\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 186s 179ms/step - loss: 0.1317 - accuracy: 0.9588\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 186s 179ms/step - loss: 0.0603 - accuracy: 0.9859\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 185s 179ms/step - loss: 0.0375 - accuracy: 0.9919\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 186s 179ms/step - loss: 0.0229 - accuracy: 0.9952\n",
            "346/346 [==============================] - 1s 2ms/step - loss: 0.6387 - accuracy: 0.8265\n",
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 189s 182ms/step - loss: 0.4443 - accuracy: 0.7927\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 188s 181ms/step - loss: 0.2638 - accuracy: 0.9035\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 188s 181ms/step - loss: 0.1325 - accuracy: 0.9595\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 188s 181ms/step - loss: 0.0665 - accuracy: 0.9827\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 188s 181ms/step - loss: 0.0424 - accuracy: 0.9907\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 188s 181ms/step - loss: 0.0315 - accuracy: 0.9938\n",
            "346/346 [==============================] - 1s 2ms/step - loss: 0.6458 - accuracy: 0.8135\n",
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 189s 182ms/step - loss: 0.4364 - accuracy: 0.8034\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 189s 182ms/step - loss: 0.2710 - accuracy: 0.8992\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 188s 182ms/step - loss: 0.1446 - accuracy: 0.9546\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 188s 181ms/step - loss: 0.0700 - accuracy: 0.9812\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 188s 181ms/step - loss: 0.0383 - accuracy: 0.9915\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 188s 181ms/step - loss: 0.0258 - accuracy: 0.9951\n",
            "346/346 [==============================] - 1s 2ms/step - loss: 0.6997 - accuracy: 0.8164\n",
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 188s 181ms/step - loss: 0.4408 - accuracy: 0.7974\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 188s 181ms/step - loss: 0.2655 - accuracy: 0.8998\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 187s 180ms/step - loss: 0.1274 - accuracy: 0.9587\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 187s 180ms/step - loss: 0.0513 - accuracy: 0.9876\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 187s 180ms/step - loss: 0.0350 - accuracy: 0.9920\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 186s 180ms/step - loss: 0.0252 - accuracy: 0.9947\n",
            "346/346 [==============================] - 1s 2ms/step - loss: 0.5880 - accuracy: 0.8327\n",
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 186s 179ms/step - loss: 0.4542 - accuracy: 0.7899\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 185s 179ms/step - loss: 0.2905 - accuracy: 0.8890\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 185s 179ms/step - loss: 0.1586 - accuracy: 0.9475\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 186s 179ms/step - loss: 0.0683 - accuracy: 0.9815\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 186s 179ms/step - loss: 0.0370 - accuracy: 0.9918\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 186s 180ms/step - loss: 0.0290 - accuracy: 0.9940\n",
            "346/346 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.8276\n",
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 186s 179ms/step - loss: 0.4393 - accuracy: 0.7983\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 185s 179ms/step - loss: 0.2759 - accuracy: 0.8937\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 185s 179ms/step - loss: 0.1356 - accuracy: 0.9549\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 185s 179ms/step - loss: 0.0548 - accuracy: 0.9856\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 186s 179ms/step - loss: 0.0316 - accuracy: 0.9926\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 186s 179ms/step - loss: 0.0207 - accuracy: 0.9957\n",
            "346/346 [==============================] - 1s 2ms/step - loss: 0.6456 - accuracy: 0.8276\n",
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 185s 178ms/step - loss: 0.4509 - accuracy: 0.7881\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 184s 178ms/step - loss: 0.2866 - accuracy: 0.8923\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 184s 177ms/step - loss: 0.1602 - accuracy: 0.9487\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 183s 177ms/step - loss: 0.0732 - accuracy: 0.9794\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 185s 178ms/step - loss: 0.0292 - accuracy: 0.9928\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 184s 177ms/step - loss: 0.0173 - accuracy: 0.9964\n",
            "346/346 [==============================] - 1s 2ms/step - loss: 0.7643 - accuracy: 0.8211\n",
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 186s 180ms/step - loss: 0.5503 - accuracy: 0.7669\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 186s 180ms/step - loss: 0.3518 - accuracy: 0.8883\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 186s 180ms/step - loss: 0.2320 - accuracy: 0.9340\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 186s 180ms/step - loss: 0.1814 - accuracy: 0.9502\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 186s 179ms/step - loss: 0.1669 - accuracy: 0.9545\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 186s 179ms/step - loss: 0.1527 - accuracy: 0.9593\n",
            "346/346 [==============================] - 1s 2ms/step - loss: 0.5629 - accuracy: 0.8383\n",
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 184s 177ms/step - loss: 0.4891 - accuracy: 0.7825\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 183s 177ms/step - loss: 0.2895 - accuracy: 0.8915\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 183s 177ms/step - loss: 0.1623 - accuracy: 0.9532\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 183s 177ms/step - loss: 0.1038 - accuracy: 0.9734\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 183s 177ms/step - loss: 0.0734 - accuracy: 0.9803\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 184s 178ms/step - loss: 0.0531 - accuracy: 0.9842\n",
            "346/346 [==============================] - 1s 2ms/step - loss: 0.6170 - accuracy: 0.8296\n",
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 184s 178ms/step - loss: 0.4459 - accuracy: 0.7948\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 184s 177ms/step - loss: 0.2797 - accuracy: 0.8932\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 184s 178ms/step - loss: 0.1281 - accuracy: 0.9593\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 184s 178ms/step - loss: 0.0490 - accuracy: 0.9876\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 185s 178ms/step - loss: 0.0299 - accuracy: 0.9943\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 185s 178ms/step - loss: 0.0198 - accuracy: 0.9960\n",
            "346/346 [==============================] - 1s 2ms/step - loss: 0.7215 - accuracy: 0.8263\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed: 298.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "1381/1381 [==============================] - 249s 180ms/step - loss: 0.4276 - accuracy: 0.8059\n",
            "Epoch 2/6\n",
            "1381/1381 [==============================] - 248s 180ms/step - loss: 0.2768 - accuracy: 0.8949\n",
            "Epoch 3/6\n",
            "1381/1381 [==============================] - 249s 180ms/step - loss: 0.1535 - accuracy: 0.9463\n",
            "Epoch 4/6\n",
            "1381/1381 [==============================] - 249s 180ms/step - loss: 0.0728 - accuracy: 0.9727\n",
            "Epoch 5/6\n",
            "1381/1381 [==============================] - 249s 181ms/step - loss: 0.0367 - accuracy: 0.9880\n",
            "Epoch 6/6\n",
            "1381/1381 [==============================] - 250s 181ms/step - loss: 0.0236 - accuracy: 0.9918\n",
            "461/461 [==============================] - 1s 2ms/step - loss: 0.7916 - accuracy: 0.8300\n",
            "0.8299837112426758\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBi6qR5BpMSW",
        "outputId": "f200ba70-6457-4044-c6f7-6e2b49c7184b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Save and evaluate results\n",
        "s = ('Running data set\\nBest Accuracy : {:.4f}\\n{}\\nTest Accuracy : {:.4f}\\n\\n')\n",
        "output_string = s.format( grid_result.best_score_, grid_result.best_params_, test_accuracy)\n",
        "print(output_string)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running data set\n",
            "Best Accuracy : 0.8288\n",
            "{'vocab_size': 192727, 'num_filters': 128, 'maxlen': 100, 'kernel_size': 7, 'embedding_dim': 100}\n",
            "Test Accuracy : 0.8300\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBC_AW1xBtGC",
        "outputId": "e485d319-2d1b-4723-f8c0-a17e6a060da5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Using code modified from https://machinelearningmastery.com/how-to-calculate-precision-recall-f1-and-more-for-deep-learning-models/\n",
        "\n",
        "pred = grid.predict(X_test)\n",
        "pred = np.rint(pred)\n",
        "\n",
        "# Precision Score\n",
        "precision = precision_score(y_test, pred)\n",
        "print('Test Precision: %f' % (precision*100))\n",
        "\n",
        "# Recall Score\n",
        "recall = recall_score(y_test, pred)\n",
        "print('Test Recall: %f' % (recall*100))\n",
        "\n",
        "# F1 Score\n",
        "f1 = f1_score(y_test, pred)\n",
        "print('Test F1 score: %f' % (f1*100))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Precision: 82.989691\n",
            "Test Recall: 76.134931\n",
            "Test F1 score: 79.414666\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}