{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of attempt2_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1aUF05bn3e3vI9r08XtoDkT1UqaTrTYSD",
      "authorship_tag": "ABX9TyP48ai2TtP3lxroAM29g/BP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krystaldowling/MAST30034_Final_Project-/blob/CNN_Model/Standard_CNN_GridSearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1-HosE7V5wu"
      },
      "source": [
        "This document contains code modified from https://realpython.com/python-keras-text-classification/. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trD-9g79UzrQ"
      },
      "source": [
        "# Import statements\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKqPoZiXboFq",
        "outputId": "bf67e6e8-98db-4a84-e29a-4a4bfbc99d2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "# Loading in preproccessed data\n",
        "PATH = \"/content/drive/My Drive/Data/\"\n",
        "data = pd.read_csv(PATH + \"preproccessed_data.csv\", lineterminator='\\n')\n",
        "\n",
        "data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>muslims busted stole millions gov ’ benefits</td>\n",
              "      <td>print pay back money plus interest entire fami...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>attorney general loretta lynch plead fifth</td>\n",
              "      <td>attorney general loretta lynch plead fifth bar...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>breaking weiner cooperating fbi hillary email ...</td>\n",
              "      <td>red state fox news sunday reported morning ant...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pin drop speech father daughter kidnapped kill...</td>\n",
              "      <td>email kayla mueller prisoner tortured isis cha...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fantastic trumps 7 point plan reform healthcar...</td>\n",
              "      <td>email healthcare reform make america great sin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29449</th>\n",
              "      <td>process analytical instruments market – techna...</td>\n",
              "      <td>technavio published new report global process ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29450</th>\n",
              "      <td>travel deals get 1200 air credit two apt cookt...</td>\n",
              "      <td>apt offering savings new cape york outback wil...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29451</th>\n",
              "      <td>taiwanese recyclers belief waste simply mispla...</td>\n",
              "      <td>taipei taiwan sept 8 2015 prnewswire recent ye...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29452</th>\n",
              "      <td>season curtain raiser ideal way honour john</td>\n",
              "      <td>blackburn sunday league john haydock memorial ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29453</th>\n",
              "      <td>four cooper standard facilities promote north ...</td>\n",
              "      <td>novi mich sept 30 2015 prnewswire four cooper ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29454 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   title  ... label\n",
              "0           muslims busted stole millions gov ’ benefits  ...     1\n",
              "1             attorney general loretta lynch plead fifth  ...     1\n",
              "2      breaking weiner cooperating fbi hillary email ...  ...     1\n",
              "3      pin drop speech father daughter kidnapped kill...  ...     1\n",
              "4      fantastic trumps 7 point plan reform healthcar...  ...     1\n",
              "...                                                  ...  ...   ...\n",
              "29449  process analytical instruments market – techna...  ...     0\n",
              "29450  travel deals get 1200 air credit two apt cookt...  ...     0\n",
              "29451  taiwanese recyclers belief waste simply mispla...  ...     0\n",
              "29452        season curtain raiser ideal way honour john  ...     0\n",
              "29453  four cooper standard facilities promote north ...  ...     0\n",
              "\n",
              "[29454 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36438kdFcw4S"
      },
      "source": [
        "# Performing test-train split\n",
        "text_train, text_test, y_train, y_test = train_test_split(data['text'].values, data['label'].values, test_size=0.25, random_state=1000)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJI8z1BGsb1h"
      },
      "source": [
        "# calculate the maximum document length\n",
        "def max_length(lines):\n",
        "\treturn max([len(s.split()) for s in lines])\n",
        " \n",
        "maxlen = max_length(data['text'])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQYfsMDoc_LD"
      },
      "source": [
        "# Tokenizing data\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(text_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(text_train)\n",
        "X_test = tokenizer.texts_to_sequences(text_test)\n",
        "\n",
        "# Vocab size- adding 1 because of reserved 0 index\n",
        "vocab_size = len(tokenizer.word_index) + 1  "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EDjazuKdi1R"
      },
      "source": [
        "# Padding sequences\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaMXS3QdCinA"
      },
      "source": [
        "# Create Model\n",
        "def create_model(num_filters, kernel_size, vocab_size, embedding_dim, maxlen):\n",
        "    model = Sequential()\n",
        "    model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
        "    model.add(layers.Conv1D(num_filters, kernel_size, activation='relu'))\n",
        "    model.add(layers.GlobalMaxPooling1D())\n",
        "    model.add(layers.Dense(6, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzvfInxSo0r2"
      },
      "source": [
        "# Defining possible parameters \n",
        "param_grid = dict(num_filters=[32, 64, 128],\n",
        "                  kernel_size=[3, 5, 7],\n",
        "                  vocab_size= [vocab_size], \n",
        "                  embedding_dim=[100],\n",
        "                  maxlen= [maxlen])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o42bxuT7fUrB",
        "outputId": "1ffd45ab-7153-41b6-c9e8-1996264f2bb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Run grid search on data\n",
        "model = KerasClassifier(build_fn=create_model, epochs=6, batch_size=16)\n",
        "grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid, cv=4, verbose=1, n_iter=4)\n",
        "# Fitting Model\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate testing set\n",
        "test_accuracy = grid.score(X_test, y_test)\n",
        "print(test_accuracy)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 193s 187ms/step - loss: 0.3972 - accuracy: 0.8195\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 193s 186ms/step - loss: 0.2066 - accuracy: 0.9262\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 192s 186ms/step - loss: 0.0801 - accuracy: 0.9773\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 192s 185ms/step - loss: 0.0234 - accuracy: 0.9956\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 191s 184ms/step - loss: 0.0135 - accuracy: 0.9976\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 191s 185ms/step - loss: 0.0078 - accuracy: 0.9982\n",
            "346/346 [==============================] - 2s 5ms/step - loss: 0.5558 - accuracy: 0.8682\n",
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 192s 185ms/step - loss: 0.3811 - accuracy: 0.8284\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 191s 184ms/step - loss: 0.2027 - accuracy: 0.9258\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 190s 184ms/step - loss: 0.0824 - accuracy: 0.9754\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 189s 183ms/step - loss: 0.0316 - accuracy: 0.9923\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 189s 182ms/step - loss: 0.0151 - accuracy: 0.9968\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 189s 183ms/step - loss: 0.0101 - accuracy: 0.9984\n",
            "346/346 [==============================] - 2s 4ms/step - loss: 0.5021 - accuracy: 0.8714\n",
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 193s 187ms/step - loss: 0.3968 - accuracy: 0.8179\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 193s 186ms/step - loss: 0.2164 - accuracy: 0.9224\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 192s 186ms/step - loss: 0.1073 - accuracy: 0.9658\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 192s 185ms/step - loss: 0.0473 - accuracy: 0.9861\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 192s 185ms/step - loss: 0.0182 - accuracy: 0.9960\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 190s 184ms/step - loss: 0.0117 - accuracy: 0.9979\n",
            "346/346 [==============================] - 1s 4ms/step - loss: 0.4960 - accuracy: 0.8674\n",
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 189s 182ms/step - loss: 0.3876 - accuracy: 0.8285\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 188s 182ms/step - loss: 0.2137 - accuracy: 0.9241\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 187s 180ms/step - loss: 0.1056 - accuracy: 0.9691\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 186s 180ms/step - loss: 0.0446 - accuracy: 0.9881\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 185s 179ms/step - loss: 0.0222 - accuracy: 0.9955\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 186s 179ms/step - loss: 0.0142 - accuracy: 0.9975\n",
            "346/346 [==============================] - 1s 4ms/step - loss: 0.5364 - accuracy: 0.8600\n",
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 188s 181ms/step - loss: 0.3785 - accuracy: 0.8349\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 188s 181ms/step - loss: 0.2022 - accuracy: 0.9267\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 187s 181ms/step - loss: 0.0732 - accuracy: 0.9786\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 187s 180ms/step - loss: 0.0232 - accuracy: 0.9949\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 187s 181ms/step - loss: 0.0123 - accuracy: 0.9976\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 187s 181ms/step - loss: 0.0095 - accuracy: 0.9981\n",
            "346/346 [==============================] - 2s 5ms/step - loss: 0.5654 - accuracy: 0.8742\n",
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 186s 180ms/step - loss: 0.3718 - accuracy: 0.8346\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 185s 178ms/step - loss: 0.2025 - accuracy: 0.9261\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 186s 180ms/step - loss: 0.0951 - accuracy: 0.9684\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 186s 180ms/step - loss: 0.0352 - accuracy: 0.9897\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 186s 179ms/step - loss: 0.0156 - accuracy: 0.9962\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 186s 179ms/step - loss: 0.0100 - accuracy: 0.9982\n",
            "346/346 [==============================] - 2s 5ms/step - loss: 0.6467 - accuracy: 0.8532\n",
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 187s 181ms/step - loss: 0.3761 - accuracy: 0.8322\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 186s 180ms/step - loss: 0.2175 - accuracy: 0.9194\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 187s 181ms/step - loss: 0.1154 - accuracy: 0.9600\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 187s 180ms/step - loss: 0.0485 - accuracy: 0.9850\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 187s 180ms/step - loss: 0.0183 - accuracy: 0.9962\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 186s 179ms/step - loss: 0.0107 - accuracy: 0.9974\n",
            "346/346 [==============================] - 2s 5ms/step - loss: 0.5449 - accuracy: 0.8749\n",
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 186s 179ms/step - loss: 0.3752 - accuracy: 0.8336\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 186s 180ms/step - loss: 0.2068 - accuracy: 0.9252\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 186s 180ms/step - loss: 0.1085 - accuracy: 0.9647\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 186s 180ms/step - loss: 0.0478 - accuracy: 0.9849\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 186s 179ms/step - loss: 0.0242 - accuracy: 0.9941\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 186s 179ms/step - loss: 0.0138 - accuracy: 0.9970\n",
            "346/346 [==============================] - 2s 5ms/step - loss: 0.5480 - accuracy: 0.8673\n",
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 176s 170ms/step - loss: 0.3803 - accuracy: 0.8372\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 176s 170ms/step - loss: 0.2070 - accuracy: 0.9293\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 177s 171ms/step - loss: 0.1130 - accuracy: 0.9670\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 176s 170ms/step - loss: 0.0705 - accuracy: 0.9808\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 176s 170ms/step - loss: 0.0418 - accuracy: 0.9893\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 177s 171ms/step - loss: 0.0157 - accuracy: 0.9964\n",
            "346/346 [==============================] - 2s 5ms/step - loss: 0.4980 - accuracy: 0.8720\n",
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 178s 171ms/step - loss: 0.3896 - accuracy: 0.8237\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 177s 171ms/step - loss: 0.2045 - accuracy: 0.9282\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 177s 171ms/step - loss: 0.1095 - accuracy: 0.9670\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 176s 170ms/step - loss: 0.0678 - accuracy: 0.9793\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 176s 170ms/step - loss: 0.0322 - accuracy: 0.9909\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 176s 170ms/step - loss: 0.0131 - accuracy: 0.9971\n",
            "346/346 [==============================] - 2s 4ms/step - loss: 0.5590 - accuracy: 0.8707\n",
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 175s 169ms/step - loss: 0.3752 - accuracy: 0.8342\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 175s 169ms/step - loss: 0.1971 - accuracy: 0.9279\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 175s 169ms/step - loss: 0.0770 - accuracy: 0.9756\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 175s 169ms/step - loss: 0.0324 - accuracy: 0.9934\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 175s 169ms/step - loss: 0.0134 - accuracy: 0.9976\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 175s 169ms/step - loss: 0.0108 - accuracy: 0.9976\n",
            "346/346 [==============================] - 2s 4ms/step - loss: 0.4845 - accuracy: 0.8747\n",
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 176s 170ms/step - loss: 0.3833 - accuracy: 0.8286\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 177s 171ms/step - loss: 0.2242 - accuracy: 0.9182\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 177s 171ms/step - loss: 0.1163 - accuracy: 0.9630\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 176s 170ms/step - loss: 0.0485 - accuracy: 0.9866\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 176s 170ms/step - loss: 0.0197 - accuracy: 0.9958\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 177s 171ms/step - loss: 0.0113 - accuracy: 0.9979\n",
            "346/346 [==============================] - 2s 5ms/step - loss: 0.5261 - accuracy: 0.8658\n",
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 180s 174ms/step - loss: 0.3811 - accuracy: 0.8308\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 182s 175ms/step - loss: 0.2080 - accuracy: 0.9276\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 179s 172ms/step - loss: 0.1078 - accuracy: 0.9671\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 176s 170ms/step - loss: 0.0524 - accuracy: 0.9852\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 174s 168ms/step - loss: 0.0252 - accuracy: 0.9941\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 174s 168ms/step - loss: 0.0130 - accuracy: 0.9976\n",
            "346/346 [==============================] - 2s 4ms/step - loss: 0.5167 - accuracy: 0.8729\n",
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 179s 173ms/step - loss: 0.3843 - accuracy: 0.8309\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 179s 173ms/step - loss: 0.2134 - accuracy: 0.9242\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 179s 173ms/step - loss: 0.1245 - accuracy: 0.9638\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 179s 173ms/step - loss: 0.0824 - accuracy: 0.9761\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 179s 172ms/step - loss: 0.0561 - accuracy: 0.9830\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 178s 172ms/step - loss: 0.0335 - accuracy: 0.9903\n",
            "346/346 [==============================] - 2s 5ms/step - loss: 0.4776 - accuracy: 0.8700\n",
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 181s 175ms/step - loss: 0.4019 - accuracy: 0.8127\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 181s 175ms/step - loss: 0.2200 - accuracy: 0.9227\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 181s 175ms/step - loss: 0.1214 - accuracy: 0.9624\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 182s 176ms/step - loss: 0.0688 - accuracy: 0.9800\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 182s 175ms/step - loss: 0.0362 - accuracy: 0.9894\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 182s 176ms/step - loss: 0.0185 - accuracy: 0.9958\n",
            "346/346 [==============================] - 1s 4ms/step - loss: 0.4623 - accuracy: 0.8731\n",
            "Epoch 1/6\n",
            "1036/1036 [==============================] - 176s 170ms/step - loss: 0.3846 - accuracy: 0.8276\n",
            "Epoch 2/6\n",
            "1036/1036 [==============================] - 176s 170ms/step - loss: 0.2214 - accuracy: 0.9186\n",
            "Epoch 3/6\n",
            "1036/1036 [==============================] - 177s 171ms/step - loss: 0.1096 - accuracy: 0.9646\n",
            "Epoch 4/6\n",
            "1036/1036 [==============================] - 177s 171ms/step - loss: 0.0401 - accuracy: 0.9887\n",
            "Epoch 5/6\n",
            "1036/1036 [==============================] - 177s 171ms/step - loss: 0.0184 - accuracy: 0.9964\n",
            "Epoch 6/6\n",
            "1036/1036 [==============================] - 176s 170ms/step - loss: 0.0151 - accuracy: 0.9976\n",
            "346/346 [==============================] - 1s 4ms/step - loss: 0.5177 - accuracy: 0.8741\n",
            "Epoch 1/6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed: 293.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1381/1381 [==============================] - 234s 169ms/step - loss: 0.3584 - accuracy: 0.8441\n",
            "Epoch 2/6\n",
            "1381/1381 [==============================] - 233s 169ms/step - loss: 0.2078 - accuracy: 0.9254\n",
            "Epoch 3/6\n",
            "1381/1381 [==============================] - 233s 169ms/step - loss: 0.1195 - accuracy: 0.9614\n",
            "Epoch 4/6\n",
            "1381/1381 [==============================] - 233s 169ms/step - loss: 0.0740 - accuracy: 0.9761\n",
            "Epoch 5/6\n",
            "1381/1381 [==============================] - 234s 169ms/step - loss: 0.0391 - accuracy: 0.9883\n",
            "Epoch 6/6\n",
            "1381/1381 [==============================] - 234s 169ms/step - loss: 0.0231 - accuracy: 0.9943\n",
            "461/461 [==============================] - 2s 4ms/step - loss: 0.5425 - accuracy: 0.8725\n",
            "0.8724877834320068\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBi6qR5BpMSW",
        "outputId": "43797942-22bd-457e-e2ea-feff2313f1c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Save and evaluate results\n",
        "s = ('Running data set\\nBest Accuracy : {:.4f}\\n{}\\nTest Accuracy : {:.4f}\\n\\n')\n",
        "output_string = s.format( grid_result.best_score_, grid_result.best_params_, test_accuracy)\n",
        "print(output_string)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running data set\n",
            "Best Accuracy : 0.8725\n",
            "{'vocab_size': 192727, 'num_filters': 64, 'maxlen': 2202, 'kernel_size': 3, 'embedding_dim': 100}\n",
            "Test Accuracy : 0.8725\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBC_AW1xBtGC",
        "outputId": "c7e7d05f-154d-47a2-c7a3-de1767936227",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Using code modified from https://machinelearningmastery.com/how-to-calculate-precision-recall-f1-and-more-for-deep-learning-models/\n",
        "\n",
        "pred = grid.predict(X_test)\n",
        "pred = np.rint(pred)\n",
        "\n",
        "# Precision Score\n",
        "precision = precision_score(y_test, pred)\n",
        "print('Test Precision: %f' % (precision*100))\n",
        "\n",
        "# Recall Score\n",
        "recall = recall_score(y_test, pred)\n",
        "print('Test Recall: %f' % (recall*100))\n",
        "\n",
        "# F1 Score\n",
        "f1 = f1_score(y_test, pred)\n",
        "print('Test F1 score: %f' % (f1*100))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "Test Precision: 87.006961\n",
            "Test Recall: 82.755359\n",
            "Test F1 score: 84.827921\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}