{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attempt2_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "11NyaBWIO25_-2valo5SYpTr3jONkoZsp",
      "authorship_tag": "ABX9TyMFxWzVMTbZyzfLqlvw9gTg"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "trD-9g79UzrQ"
      },
      "source": [
        "# Import statements\n",
        "import pandas as pd\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKqPoZiXboFq",
        "outputId": "7f569d90-3b8e-4cbc-c1ac-a42599a989db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "# Loading in preproccessed data\n",
        "PATH = \"/content/drive/My Drive/Data/\"\n",
        "\n",
        "# create dataframes and keep only necessary features to join dataframes\n",
        "data = pd.read_csv(PATH + \"preproccessed_data.csv\", lineterminator='\\n')\n",
        "\n",
        "data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>muslims busted stole millions gov ’ benefits</td>\n",
              "      <td>print pay back money plus interest entire fami...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>attorney general loretta lynch plead fifth</td>\n",
              "      <td>attorney general loretta lynch plead fifth bar...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>breaking weiner cooperating fbi hillary email ...</td>\n",
              "      <td>red state fox news sunday reported morning ant...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pin drop speech father daughter kidnapped kill...</td>\n",
              "      <td>email kayla mueller prisoner tortured isis cha...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fantastic trumps 7 point plan reform healthcar...</td>\n",
              "      <td>email healthcare reform make america great sin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29449</th>\n",
              "      <td>process analytical instruments market – techna...</td>\n",
              "      <td>technavio published new report global process ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29450</th>\n",
              "      <td>travel deals get 1200 air credit two apt cookt...</td>\n",
              "      <td>apt offering savings new cape york outback wil...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29451</th>\n",
              "      <td>taiwanese recyclers belief waste simply mispla...</td>\n",
              "      <td>taipei taiwan sept 8 2015 prnewswire recent ye...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29452</th>\n",
              "      <td>season curtain raiser ideal way honour john</td>\n",
              "      <td>blackburn sunday league john haydock memorial ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29453</th>\n",
              "      <td>four cooper standard facilities promote north ...</td>\n",
              "      <td>novi mich sept 30 2015 prnewswire four cooper ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29454 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   title  ... label\n",
              "0           muslims busted stole millions gov ’ benefits  ...     1\n",
              "1             attorney general loretta lynch plead fifth  ...     1\n",
              "2      breaking weiner cooperating fbi hillary email ...  ...     1\n",
              "3      pin drop speech father daughter kidnapped kill...  ...     1\n",
              "4      fantastic trumps 7 point plan reform healthcar...  ...     1\n",
              "...                                                  ...  ...   ...\n",
              "29449  process analytical instruments market – techna...  ...     0\n",
              "29450  travel deals get 1200 air credit two apt cookt...  ...     0\n",
              "29451  taiwanese recyclers belief waste simply mispla...  ...     0\n",
              "29452        season curtain raiser ideal way honour john  ...     0\n",
              "29453  four cooper standard facilities promote north ...  ...     0\n",
              "\n",
              "[29454 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1-HosE7V5wu"
      },
      "source": [
        "https://realpython.com/python-keras-text-classification/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36438kdFcw4S",
        "outputId": "8f4b46c8-7061-4270-9a5f-4a630ecdae66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "text = data['text'].values\n",
        "label = data['label'].values\n",
        "\n",
        "text_train, text_test, y_train, y_test = train_test_split(text, label, test_size=0.25, random_state=1000)\n",
        "\n",
        "print(text_train[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "also stories click phrases see list subjects places carson city nevada — amount taxable sales nevada jumped 8 percent july compared month year ago nevada department taxation reported tuesday 43 billion taxable sales nevada july nearly 337 million taxes collected sales 85 million went state general fund general fund sales tax revenue coming slightly higher economists predicted would made economic forum forecast may sectors showing big gains included auto parts dealers sales 14 percent restaurant bar sales 9 percent food beverage store sales 10 percent\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQYfsMDoc_LD",
        "outputId": "043724f1-82ac-4c58-a52b-8158b27601f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(text_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(text_train)\n",
        "X_test = tokenizer.texts_to_sequences(text_test)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
        "\n",
        "print(text_train[2])\n",
        "print(X_train[2])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "firearms panics happen variety things like acts domestic terrorism mass shootings democrats getting elected office though may worry years nd amendment enthusiast donald trumps decisive victory last night lets cover bases talk panic future democrats electedwhat panic ammo firearms panic people go buy items worried soon illegal buy sell items maybe already americans still believe ex post facto laws part constitutionadding panic speculators buy retailers roundly shamed raise prices resell privately much higher levels legal certainly isnt ethical decent thing folks deserve shamed mocked every opportunitylastly gun stores sites inventory handle flex buying demand manufacturer artificially contrived panic creates real scarcity corrected panic running steam everyone buys consider enough natural undercutting resets price back lower levelssome prices never return long rifle ammunition still totally recovered damage old brock islamic shock obama multiyear championship best firearms salesman ever may even worse bitch chiefso gets grabbed panic get count still available weve got three categories guns ammo componentsaccessoriesguns anything thats big liberal hit list first target ban first target panic look things popular right scary left also look things modern one going ban garand anytime soonevil features matter destructive power anyone knows anything guns knows ak ar fire intermediate cartridges puny enough considered inhumane several states hunt deer lack power kill animal marginal shots however theyre black mean things attached theyre shit list nice blued wooden stock scoped bolt action rifle magnum cartridge capable wrecking world twice distance ar pull safe looks traditionalthey popular left get noticed rifles like fal anything based ghk action simply dont enough exposure get targeted unless pull something sweeping like usc r rules mini might safe maybefor pistols pretty much semiautomatic polymer age fair game want banned oftentimes stupid rules like restrictive magazine sizes get pushed hi powers old domestic semiautos revolvers safe expect libtards go glocks likeshotguns seem immune days theres whole lot difference hunting gun combat gun paint mag tube length think saigas still imported box mag fed one anything else makes good home defense gun also immune ammo panic portion wellammunition range full metal jacket defensehunting hollow soft point cartridges popular centerfire calibers long rifle almost literally evaporate local store online probably beginning write thisoddly enough certain rounds suffer panic buying rifles limited traditional hunting rounds like seem impacted doesnt get bought panic old joke goes men dont panic really feedback cycle mentioned start theres little demand exceed instore supply perception gone good occureverything shotgun shell howitzer round far right sell fast panicpanic bought pistol ammo big mm luger sw acp round affected semiautomatic rounds usually bit run magnum special well mm sig gap magnums like seem affectedfor rimfires long rifle goes poof magnum brother smaller caliber cousins seem affected rimfires reloadable contributes overstockpilingcomponents accessories centerfire ammo reloadable serious amongst shooters roll economy selfreliance performance consumable components also get panics although ive held reloading articles get press set back hit components get panic bought brieflybiggest thing primers even bigger bullets oddly enough primer little metal cup gets smacked firing pin sets powder modern cartridges come two sizes pistols two rifles varying hardness satisfy military specificationsthe second gunpowder fortunately theres wide variety smokeless powder everyone tends brands formulas prefer takes little less hit primers third bullets since many types manufacturers also take little less hit primers obviously need three reload bear mind always save brass anyone elses pick upeven though little ones easier use higher capacity ones disappear first get bothwhile always good idea spare springs small parts like firing pins extractors prone breakage number one accessory part take hit panics box magazine especially high capacity ones dont mean round drum mags although take dive really mean round coffin mags mean full capacity full sized pistol mags like round mag full sized pistol round ar mag expect see pmags surplus style aluminum ar mags vanish gabby giffords special extended glock round mag also contender vanishing fast panicholsters slings cleaning accessories optics ammo cans seem immune panicswhat already carbine andor semiauto pistol make sure enough ammo magazines spare parts lot better one gun multiple mags lot ammo many guns one two mags came factory couple boxes ammoi try least six mags semiauto pistols least ten mags semiauto rifles get rifle mags different sizes ar mags fun shooting standing get way prone firing rounders preferableyour ultimate ammo goal maintain thousand practice rounds defense rounds gun prepanic panic situation get normal price better none youre reloading know get alreadyif dont anything want soon refer pistol articles rifle article shotgun article buying guide consider buying stripped ar lowers build rainy day later onbuild ar meet girls rangeconclusion matter got elected think country rough times always better firearms need need store safely accessible ready times need read firearms man\n",
            "[4679, 725, 2203, 147, 14, 1928, 1389, 906, 894, 3457, 232, 403, 771, 131, 172, 35, 2170, 24, 1529, 62, 1935, 523, 26, 206, 3736, 1130, 4465, 481, 3648, 332, 232, 3648, 4679, 3648, 10, 84, 821, 2412, 1941, 577, 535, 821, 1401, 2412, 859, 158, 165, 66, 230, 236, 781, 89, 3648, 821, 1298, 1288, 4139, 48, 691, 1090, 402, 947, 3462, 255, 2702, 3472, 100, 801, 2450, 1515, 2630, 2219, 1170, 3648, 3895, 198, 3648, 542, 461, 945, 257, 985, 584, 45, 979, 1288, 98, 708, 99, 4969, 66, 2278, 4537, 1193, 409, 348, 2798, 39, 3338, 184, 4679, 269, 35, 22, 1184, 998, 3648, 34, 2256, 66, 633, 195, 96, 1938, 386, 1747, 181, 896, 605, 502, 21, 1100, 939, 21, 1100, 3648, 177, 147, 655, 79, 132, 12, 177, 147, 1132, 8, 42, 939, 2165, 351, 111, 496, 1142, 386, 1938, 1142, 607, 257, 844, 155, 25, 1089, 111, 1446, 2821, 2976, 191, 3797, 148, 648, 147, 3797, 502, 1778, 1050, 482, 4969, 2925, 30, 1804, 3136, 2124, 955, 1124, 655, 132, 34, 3026, 14, 386, 387, 482, 554, 1004, 257, 3389, 34, 1905, 1667, 2124, 140, 4689, 14, 1326, 658, 124, 955, 1024, 48, 710, 1413, 302, 69, 2720, 3277, 658, 14, 1414, 34, 1700, 1744, 409, 1389, 955, 1152, 84, 878, 3999, 129, 3288, 644, 215, 1538, 801, 2089, 801, 4652, 4707, 50, 66, 2079, 1229, 8, 386, 668, 485, 88, 113, 421, 801, 12, 3999, 3648, 3584, 1383, 336, 3490, 4080, 187, 655, 99, 4969, 346, 2431, 280, 1210, 505, 553, 1062, 1530, 257, 695, 4784, 3769, 3648, 2219, 1244, 1194, 4784, 14, 878, 2608, 34, 1833, 3648, 409, 3048, 797, 204, 1004, 3648, 128, 2532, 2023, 362, 3288, 163, 1170, 1732, 4565, 978, 88, 1578, 154, 79, 1401, 1797, 1833, 181, 1578, 2125, 4784, 1367, 937, 339, 526, 58, 2996, 14, 878, 99, 4969, 797, 1521, 2056, 878, 2125, 718, 3167, 442, 1064, 12, 34, 533, 4040, 426, 1400, 34, 285, 209, 45, 605, 34, 3648, 1833, 255, 22, 1821, 4504, 257, 163, 3490, 2239, 998, 3434, 3370, 1132, 117, 23, 23, 118, 259, 3288, 1913, 2203, 461, 3359, 3940, 855, 163, 194, 605, 567, 4504, 54, 20, 2600, 3979, 12, 64, 163, 194, 605, 2018, 103, 96, 2406, 616, 247, 1304, 496, 1622, 172, 163, 996, 2198, 94, 691, 2364, 996, 21, 34, 247, 88, 476, 316, 1060, 14, 3434, 170, 8, 89, 64, 605, 2079, 1414, 460, 208, 2364, 996, 1004, 648, 1578, 533, 64, 128, 648, 1578, 648, 336, 2364, 336, 14, 1578, 336, 1578, 1152, 57, 2146, 526, 2849, 1578, 12, 1797, 878, 3999, 158, 4991, 40, 446, 257, 1060, 215, 213, 8, 801, 1098, 215, 20, 1938, 8, 23, 188, 3438, 987, 489, 183, 486, 183, 2381, 34, 4969, 260, 1891, 1042, 803, 34, 44, 3434, 3234, 1041, 2042, 3512, 1224, 4784, 421, 4784, 801, 3648, 680, 34, 1697, 584, 213, 1350, 3530, 51, 34, 1004, 386, 69, 577, 4752, 1400, 4969, 301, 301, 2219, 2816, 945, 2219, 864, 49, 182, 948, 1387, 351, 195, 771, 50, 41, 72, 247, 213, 4679, 103, 103, 1210, 1085, 72, 103, 373, 4679, 121]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EDjazuKdi1R",
        "outputId": "7ccab903-2102-4afc-c8bd-8ddabf5c27db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "maxlen = 100\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
        "\n",
        "print(X_train[0, :])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  12  838 1375   57  502 4517 1134   77 2725    7  972  884 2725 4106\n",
            "  578   59  757 1253  243   29  228 2725  116  174  262 3768  392  884\n",
            " 2725  757  363   82 1386 3526  884 4859   82  279   19  161  958  161\n",
            "  958  884  390 1845  385 2672  691 4045 2531    9   43  264 2984 4896\n",
            "   35 1189  181 3092  776 4503 1060  884 1057   59 1931 1759  884  851\n",
            "   59  376 1210  884  223   59    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz5e2Xm9dxwO"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "def plot_history(history):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    x = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x, acc, 'b', label='Training acc')\n",
        "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, loss, 'b', label='Training loss')\n",
        "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaMXS3QdCinA",
        "outputId": "e43e259c-1caa-4ab1-a314-cb2f34566e8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "\n",
        "embedding_dim = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
        "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_20 (Embedding)     (None, 100, 100)          19272700  \n",
            "_________________________________________________________________\n",
            "conv1d_20 (Conv1D)           (None, 96, 128)           64128     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_20 (Glo (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 19,338,129\n",
            "Trainable params: 19,338,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o42bxuT7fUrB"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs = 6,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=32)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
        "plot_history(history)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75A9r77fCmxc"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "\n",
        "def create_model(num_filters, kernel_size, vocab_size, embedding_dim, maxlen):\n",
        "    model = Sequential()\n",
        "    model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
        "    model.add(layers.Conv1D(num_filters, kernel_size, activation='relu'))\n",
        "    model.add(layers.GlobalMaxPooling1D())\n",
        "    model.add(layers.Dense(6, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPW_mcYfPMeA"
      },
      "source": [
        "param_grid = dict(num_filters=[32, 64, 128],\n",
        "                  kernel_size=[3, 5, 7],\n",
        "                  vocab_size=[5000], \n",
        "                  embedding_dim=[50],\n",
        "                  maxlen=[100])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o09nASoq4qw9"
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Main settings\n",
        "epochs = 6\n",
        "embedding_dim = 50\n",
        "maxlen = 100\n",
        "\n",
        "# Run grid search for each source (yelp, amazon, imdb)\n",
        "model = KerasClassifier(build_fn=create_model, epochs=epochs, batch_size=32, verbose=False)\n",
        "grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid, cv=4, verbose=1, n_iter=5)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate testing set\n",
        "test_accuracy = grid.score(X_test, y_test)\n",
        "\n",
        "# Save and evaluate results\n",
        "s = ('Running data set\\nBest Accuracy : {:.4f}\\n{}\\nTest Accuracy : {:.4f}\\n\\n')\n",
        "output_string = s.format( grid_result.best_score_, grid_result.best_params_, test_accuracy)\n",
        "print(output_string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBC_AW1xBtGC",
        "outputId": "cdb56af8-5f81-4331-d50d-0c2f8d197ce8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "s = ('Running data set\\nBest Accuracy : {:.4f}\\n{}\\nTest Accuracy : {:.4f}\\n\\n')\n",
        "output_string = s.format( grid_result.best_score_, grid_result.best_params_, test_accuracy)\n",
        "print(output_string)\n",
        "       "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running data set\n",
            "Best Accuracy : 0.8287\n",
            "{'vocab_size': 5000, 'num_filters': 64, 'maxlen': 100, 'kernel_size': 3, 'embedding_dim': 50}\n",
            "Test Accuracy : 0.8354\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}