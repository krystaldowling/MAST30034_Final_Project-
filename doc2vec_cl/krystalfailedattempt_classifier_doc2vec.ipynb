{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classifier_doc2vec.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujBrvVJ3nDD9",
        "outputId": "9e042926-adeb-4eab-8a24-df1a263451fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "import pickle\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "news_data = pd.read_csv(\"/content/drive/My Drive/Data/preproccessed_data.csv\")\n",
        "\n",
        "news_data.index.name = 'index'\n",
        "news_data"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>muslims busted stole millions gov ’ benefits</td>\n",
              "      <td>print pay back money plus interest entire fami...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>attorney general loretta lynch plead fifth</td>\n",
              "      <td>attorney general loretta lynch plead fifth bar...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>breaking weiner cooperating fbi hillary email ...</td>\n",
              "      <td>red state fox news sunday reported morning ant...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pin drop speech father daughter kidnapped kill...</td>\n",
              "      <td>email kayla mueller prisoner tortured isis cha...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fantastic trumps 7 point plan reform healthcar...</td>\n",
              "      <td>email healthcare reform make america great sin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29449</th>\n",
              "      <td>process analytical instruments market – techna...</td>\n",
              "      <td>technavio published new report global process ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29450</th>\n",
              "      <td>travel deals get 1200 air credit two apt cookt...</td>\n",
              "      <td>apt offering savings new cape york outback wil...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29451</th>\n",
              "      <td>taiwanese recyclers belief waste simply mispla...</td>\n",
              "      <td>taipei taiwan sept 8 2015 prnewswire recent ye...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29452</th>\n",
              "      <td>season curtain raiser ideal way honour john</td>\n",
              "      <td>blackburn sunday league john haydock memorial ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29453</th>\n",
              "      <td>four cooper standard facilities promote north ...</td>\n",
              "      <td>novi mich sept 30 2015 prnewswire four cooper ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29454 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   title  ... label\n",
              "index                                                     ...      \n",
              "0           muslims busted stole millions gov ’ benefits  ...     1\n",
              "1             attorney general loretta lynch plead fifth  ...     1\n",
              "2      breaking weiner cooperating fbi hillary email ...  ...     1\n",
              "3      pin drop speech father daughter kidnapped kill...  ...     1\n",
              "4      fantastic trumps 7 point plan reform healthcar...  ...     1\n",
              "...                                                  ...  ...   ...\n",
              "29449  process analytical instruments market – techna...  ...     0\n",
              "29450  travel deals get 1200 air credit two apt cookt...  ...     0\n",
              "29451  taiwanese recyclers belief waste simply mispla...  ...     0\n",
              "29452        season curtain raiser ideal way honour john  ...     0\n",
              "29453  four cooper standard facilities promote north ...  ...     0\n",
              "\n",
              "[29454 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JzWteUlnJbh",
        "outputId": "7c73c795-d090-464e-dd78-78698e910f7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from gensim.test.utils import common_texts\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "import gensim\n",
        "from gensim.test.utils import get_tmpfile\n",
        "\n",
        "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(common_texts)]\n",
        "model = Doc2Vec(documents, vector_size=1000, window=2, min_count=1, workers=4)\n",
        "\n",
        "fname = get_tmpfile(\"my_doc2vec_model\")\n",
        "\n",
        "\n",
        "model.save(fname)\n",
        "model = Doc2Vec.load(fname)  # you can continue training with the loaded model!\n",
        "model.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
        "\n",
        "\n",
        "def doc2vec_fun(x):\n",
        "    L = []\n",
        "    punc = ',\"»-'\n",
        "    for elem in x.split(' '):\n",
        "        if elem not in punc:\n",
        "          L.append(elem)\n",
        "    vector = model.infer_vector(L)\n",
        "    return vector\n",
        "news_data['doc2vec_title']=news_data['title'].map(lambda x:doc2vec_fun(str(x)))\n",
        "news_data['doc2vec_text']=news_data['text'].map(lambda x:doc2vec_fun(str(x)))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:252: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaZ2aCBK0L7l"
      },
      "source": [
        "# this is only the text data which has been converted to a data frame.\n",
        "# each row is one article and each column is an element of the vector. \n",
        "\n",
        "text_vectorised_data = pd.DataFrame(news_data['doc2vec_text'].array, columns = range(1000))\n",
        "title_vectorised_data = pd.DataFrame(news_data['doc2vec_title'].array, columns = range(1000))\n",
        "\n",
        "# once we have vectorised the entire datset then split into train and test! \n",
        "text_vec_train, text_vec_test, label_train, label_test = train_test_split(text_vectorised_data, news_data['label'], test_size=0.33, \n",
        "                                                        random_state=88)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEugt7aN0Mvh"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otX5SLXB0PFq",
        "outputId": "121c05a7-6e0c-401c-959f-cdfcb010a43d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "# trying different SVM kernels\n",
        "from sklearn import metrics\n",
        "\n",
        "def svm_classifier(X, y, Xtest, ytest):\n",
        "    \n",
        "    models = [SVC(kernel = 'linear'),\n",
        "             SVC(kernel = 'poly'),\n",
        "             SVC(kernel = 'rbf'),\n",
        "             SVC(kernel = 'sigmoid')]\n",
        "    \n",
        "    titles = ['SVC with linear kernel',\n",
        "            'SVC with polynomial kernel',\n",
        "             'SVC with rbf kernel',\n",
        "             'SVC with sigmoid kernel']\n",
        "\n",
        "\n",
        "    \n",
        "    # prepare the cross-validation procedure\n",
        "    cv = KFold(n_splits=4, random_state=1, shuffle=True)\n",
        "    \n",
        "    for title, model in zip(titles, models):\n",
        "        print('\\n',title, ': with doc2vec')\n",
        "        model.fit(X, y)\n",
        "        y_pred = model.predict(Xtest)\n",
        "        print(y_pred.sum())\n",
        "        print(\"Accuracy:\",metrics.accuracy_score(ytest, y_pred))\n",
        "        # Model Precision: what percentage of positive tuples are labeled as such?\n",
        "        print(\"Precision:\",metrics.precision_score(ytest, y_pred))\n",
        "        # Model Recall: what percentage of positive tuples are labelled as such?\n",
        "        print(\"Recall:\",metrics.recall_score(ytest, y_pred))\n",
        "            \n",
        "    return\n",
        "\n",
        "svm_classifier(text_vec_train, label_train, text_vec_test, label_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " SVC with linear kernel : with doc2vec\n",
            "0\n",
            "Accuracy: 0.5700617283950618\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "\n",
            " SVC with polynomial kernel : with doc2vec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEBRTbc8nO4M"
      },
      "source": [
        "# trying different SVM kernels\n",
        "\n",
        "def logreg_classifier(X, y):\n",
        "    \n",
        "\n",
        "    models = [LogisticRegression(solver = 'newton-cg'),\n",
        "             LogisticRegression(solver = 'lbfgs'),\n",
        "             LogisticRegression(solver = 'liblinear'),\n",
        "             LogisticRegression(solver = 'sag'),\n",
        "             LogisticRegression(solver = 'saga')]\n",
        "    \n",
        "    titles = ['Logistic Regression with newton-cg',\n",
        "            'Logistic Regression with lbfgs',\n",
        "             'Logistic Regression with liblinear',\n",
        "             'Logistic Regression with sag',\n",
        "             'Logistic Regression with saga']\n",
        "\n",
        "\n",
        "    \n",
        "    # prepare the cross-validation procedure\n",
        "    cv = KFold(n_splits=4, random_state=1, shuffle=True)\n",
        "    \n",
        "    for title, model in zip(titles, models):\n",
        "        print('\\n',title, ': doc2vec')\n",
        "        model = model\n",
        "        scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "        print('Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))\n",
        "            \n",
        "    return\n",
        "\n",
        "logreg_classifier(text_vectorised_data, news_data['label'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}