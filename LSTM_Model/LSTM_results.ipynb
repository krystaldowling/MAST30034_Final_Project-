{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_results",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krystaldowling/MAST30034_Final_Project-/blob/LSTM/LSTM_results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQwL-7CdRfig",
        "outputId": "20704188-491f-42bf-bb47-e44d52aa9cab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8-xzfMlOAsU"
      },
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import MaxPooling1D\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import Bidirectional\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzA0s6lrNjvM"
      },
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/Data/final_preproccessed_data.csv', lineterminator='\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PezILc3wWP2N"
      },
      "source": [
        "# tokenise data\n",
        "\n",
        "def tokeniser(data, max_len=500):\n",
        "# maximum length of the vectors is 500\n",
        "\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(data['text'])\n",
        "  # dictonary of all words in data and counts\n",
        "  word_index = tokenizer.word_index\n",
        "  # number of words in all articles in dataset\n",
        "  vocab_size = len(word_index)\n",
        "  sequences = tokenizer.texts_to_sequences(data['text'])\n",
        "  # padding data\n",
        "  padded = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "  return padded, vocab_size, word_index, tokenizer\n",
        "\n",
        "padded, vocab_size, word_index, tokenizer = tokeniser(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMQ-ZmLFWo4E"
      },
      "source": [
        "# split data into test and train sets\n",
        "\n",
        "X_train, X_test, y_train, y_test =  sklearn.model_selection.train_test_split(padded, data['label'],test_size = 0.2, random_state = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB6gDJ4kB3UU",
        "outputId": "e6703332-24e2-4974-8d74-f708783737a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# trained GloVe embeddings sourced from https://nlp.stanford.edu/projects/glove/\n",
        "\n",
        "EMBEDDING_FILE = '/content/drive/My Drive/glove.6B/glove.6B.100d.txt'\n",
        "\n",
        "# the following code has been modified from Rama Vish, October 2020, https://www.kaggle.com/raamav/useful-functions-for-text-processing-v2\n",
        "\n",
        "# get the word coefficients from file\n",
        "def get_coefs(word, *arr): \n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE))\n",
        "\n",
        "all_embs = np.stack(embeddings_index.values())\n",
        "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "embed_size = all_embs.shape[1]\n",
        "\n",
        "# create embedding matrix \n",
        "embedding_matrix = np.random.normal(emb_mean, emb_std, (vocab_size+1, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word);\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector;\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb8ZTEI_V4rn",
        "outputId": "b246bf19-8d1d-44f6-c054-08a8caf74bb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# the best - performing LSTM-CNN model\n",
        "\n",
        "model_lstm = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size+1, 100, weights=[embedding_matrix], trainable=False),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    # 1 x 5 filter for the convolutional layer\n",
        "    tf.keras.layers.Conv1D(32, 5, activation='relu',padding='same'),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=4),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    # 1 x 3 filter for the convolutional layer\n",
        "    tf.keras.layers.Conv1D(64, 3, activation='relu',padding='same'),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=4),\n",
        "    tf.keras.layers.LSTM(20, return_sequences=True),\n",
        "    tf.keras.layers.LSTM(20, return_sequences=True),\n",
        "    tf.keras.layers.LSTM(20, return_sequences=True),\n",
        "    tf.keras.layers.LSTM(20),\n",
        "    tf.keras.layers.Dropout(0.2),  \n",
        "    tf.keras.layers.Dense(256),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(128),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_lstm.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model_lstm.summary()\n",
        "\n",
        "# important to note that default shuffle is set to true so the NN doesn't memorise a sequence and increases generability\n",
        "history = model_lstm.fit(X_train, y_train, epochs=30, batch_size=50, validation_data=(X_test, y_test))\n",
        "\n",
        "#plot_model(model_lstm, show_shapes=True, to_file='/content/drive/My Drive/Data/model.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_14 (Embedding)     (None, None, 100)         23440100  \n",
            "_________________________________________________________________\n",
            "dropout_47 (Dropout)         (None, None, 100)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_10 (Conv1D)           (None, None, 32)          16032     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_10 (MaxPooling (None, None, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_48 (Dropout)         (None, None, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_11 (Conv1D)           (None, None, 64)          6208      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_11 (MaxPooling (None, None, 64)          0         \n",
            "_________________________________________________________________\n",
            "lstm_46 (LSTM)               (None, None, 20)          6800      \n",
            "_________________________________________________________________\n",
            "lstm_47 (LSTM)               (None, None, 20)          3280      \n",
            "_________________________________________________________________\n",
            "lstm_48 (LSTM)               (None, None, 20)          3280      \n",
            "_________________________________________________________________\n",
            "lstm_49 (LSTM)               (None, 20)                3280      \n",
            "_________________________________________________________________\n",
            "dropout_49 (Dropout)         (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 256)               5376      \n",
            "_________________________________________________________________\n",
            "dropout_50 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 23,517,381\n",
            "Trainable params: 77,281\n",
            "Non-trainable params: 23,440,100\n",
            "_________________________________________________________________\n",
            "Epoch 1/60\n",
            "472/472 [==============================] - 8s 17ms/step - loss: 0.5698 - accuracy: 0.7050 - val_loss: 0.4556 - val_accuracy: 0.7915\n",
            "Epoch 2/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.4253 - accuracy: 0.8109 - val_loss: 0.3807 - val_accuracy: 0.8184\n",
            "Epoch 3/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.3627 - accuracy: 0.8442 - val_loss: 0.3099 - val_accuracy: 0.8762\n",
            "Epoch 4/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.3368 - accuracy: 0.8608 - val_loss: 0.3061 - val_accuracy: 0.8762\n",
            "Epoch 5/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.3160 - accuracy: 0.8725 - val_loss: 0.3026 - val_accuracy: 0.8796\n",
            "Epoch 6/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.3062 - accuracy: 0.8777 - val_loss: 0.3166 - val_accuracy: 0.8662\n",
            "Epoch 7/60\n",
            "472/472 [==============================] - 7s 15ms/step - loss: 0.2915 - accuracy: 0.8841 - val_loss: 0.2867 - val_accuracy: 0.8891\n",
            "Epoch 8/60\n",
            "472/472 [==============================] - 7s 15ms/step - loss: 0.2847 - accuracy: 0.8875 - val_loss: 0.2793 - val_accuracy: 0.8908\n",
            "Epoch 9/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.2738 - accuracy: 0.8920 - val_loss: 0.2765 - val_accuracy: 0.8900\n",
            "Epoch 10/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.2666 - accuracy: 0.8960 - val_loss: 0.2720 - val_accuracy: 0.8937\n",
            "Epoch 11/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.2633 - accuracy: 0.8978 - val_loss: 0.2807 - val_accuracy: 0.8871\n",
            "Epoch 12/60\n",
            "472/472 [==============================] - 7s 15ms/step - loss: 0.2536 - accuracy: 0.9019 - val_loss: 0.2676 - val_accuracy: 0.8998\n",
            "Epoch 13/60\n",
            "472/472 [==============================] - 7s 15ms/step - loss: 0.2521 - accuracy: 0.9005 - val_loss: 0.2754 - val_accuracy: 0.8956\n",
            "Epoch 14/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.2453 - accuracy: 0.9045 - val_loss: 0.2647 - val_accuracy: 0.8962\n",
            "Epoch 15/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.2406 - accuracy: 0.9073 - val_loss: 0.2785 - val_accuracy: 0.9017\n",
            "Epoch 16/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.2344 - accuracy: 0.9110 - val_loss: 0.2943 - val_accuracy: 0.8798\n",
            "Epoch 17/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.2303 - accuracy: 0.9116 - val_loss: 0.2795 - val_accuracy: 0.9018\n",
            "Epoch 18/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.2351 - accuracy: 0.9092 - val_loss: 0.2801 - val_accuracy: 0.8913\n",
            "Epoch 19/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.2245 - accuracy: 0.9143 - val_loss: 0.2625 - val_accuracy: 0.8991\n",
            "Epoch 20/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.2256 - accuracy: 0.9126 - val_loss: 0.2938 - val_accuracy: 0.8935\n",
            "Epoch 21/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.2240 - accuracy: 0.9131 - val_loss: 0.2845 - val_accuracy: 0.8859\n",
            "Epoch 22/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.2229 - accuracy: 0.9131 - val_loss: 0.2649 - val_accuracy: 0.9034\n",
            "Epoch 23/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.2142 - accuracy: 0.9188 - val_loss: 0.2653 - val_accuracy: 0.9000\n",
            "Epoch 24/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.2162 - accuracy: 0.9153 - val_loss: 0.2766 - val_accuracy: 0.9006\n",
            "Epoch 25/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.2080 - accuracy: 0.9191 - val_loss: 0.2632 - val_accuracy: 0.9003\n",
            "Epoch 26/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.2094 - accuracy: 0.9188 - val_loss: 0.3025 - val_accuracy: 0.8849\n",
            "Epoch 27/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.2055 - accuracy: 0.9207 - val_loss: 0.2702 - val_accuracy: 0.9005\n",
            "Epoch 28/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.2035 - accuracy: 0.9212 - val_loss: 0.2855 - val_accuracy: 0.9015\n",
            "Epoch 29/60\n",
            "472/472 [==============================] - 7s 15ms/step - loss: 0.2065 - accuracy: 0.9195 - val_loss: 0.2646 - val_accuracy: 0.9040\n",
            "Epoch 30/60\n",
            "472/472 [==============================] - 7s 15ms/step - loss: 0.1958 - accuracy: 0.9255 - val_loss: 0.2782 - val_accuracy: 0.8917\n",
            "Epoch 31/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.2019 - accuracy: 0.9202 - val_loss: 0.2838 - val_accuracy: 0.8969\n",
            "Epoch 32/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.2016 - accuracy: 0.9229 - val_loss: 0.2797 - val_accuracy: 0.8976\n",
            "Epoch 33/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.1965 - accuracy: 0.9229 - val_loss: 0.2743 - val_accuracy: 0.9032\n",
            "Epoch 34/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.1920 - accuracy: 0.9260 - val_loss: 0.2655 - val_accuracy: 0.9010\n",
            "Epoch 35/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.1961 - accuracy: 0.9241 - val_loss: 0.2558 - val_accuracy: 0.8991\n",
            "Epoch 36/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.1936 - accuracy: 0.9254 - val_loss: 0.2804 - val_accuracy: 0.8950\n",
            "Epoch 37/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.1943 - accuracy: 0.9251 - val_loss: 0.2746 - val_accuracy: 0.8974\n",
            "Epoch 38/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.1900 - accuracy: 0.9259 - val_loss: 0.2785 - val_accuracy: 0.8954\n",
            "Epoch 39/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.1855 - accuracy: 0.9260 - val_loss: 0.2816 - val_accuracy: 0.9013\n",
            "Epoch 40/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.1905 - accuracy: 0.9257 - val_loss: 0.2825 - val_accuracy: 0.8950\n",
            "Epoch 41/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.1879 - accuracy: 0.9265 - val_loss: 0.2794 - val_accuracy: 0.9023\n",
            "Epoch 42/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.1866 - accuracy: 0.9280 - val_loss: 0.2828 - val_accuracy: 0.8913\n",
            "Epoch 43/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.1841 - accuracy: 0.9282 - val_loss: 0.2680 - val_accuracy: 0.8954\n",
            "Epoch 44/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.1822 - accuracy: 0.9292 - val_loss: 0.2867 - val_accuracy: 0.9018\n",
            "Epoch 45/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.1804 - accuracy: 0.9303 - val_loss: 0.2792 - val_accuracy: 0.9045\n",
            "Epoch 46/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.1796 - accuracy: 0.9311 - val_loss: 0.2843 - val_accuracy: 0.9017\n",
            "Epoch 47/60\n",
            "472/472 [==============================] - 7s 15ms/step - loss: 0.1838 - accuracy: 0.9276 - val_loss: 0.2670 - val_accuracy: 0.9057\n",
            "Epoch 48/60\n",
            "472/472 [==============================] - 7s 15ms/step - loss: 0.1806 - accuracy: 0.9284 - val_loss: 0.2831 - val_accuracy: 0.9005\n",
            "Epoch 49/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.1807 - accuracy: 0.9293 - val_loss: 0.2921 - val_accuracy: 0.8956\n",
            "Epoch 50/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.1770 - accuracy: 0.9307 - val_loss: 0.2845 - val_accuracy: 0.9025\n",
            "Epoch 51/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.1767 - accuracy: 0.9310 - val_loss: 0.2790 - val_accuracy: 0.9032\n",
            "Epoch 52/60\n",
            "472/472 [==============================] - 7s 15ms/step - loss: 0.1774 - accuracy: 0.9304 - val_loss: 0.2806 - val_accuracy: 0.9012\n",
            "Epoch 53/60\n",
            "472/472 [==============================] - 7s 16ms/step - loss: 0.1775 - accuracy: 0.9312 - val_loss: 0.2701 - val_accuracy: 0.9017\n",
            "Epoch 54/60\n",
            "472/472 [==============================] - 7s 15ms/step - loss: 0.1722 - accuracy: 0.9319 - val_loss: 0.2985 - val_accuracy: 0.9025\n",
            "Epoch 55/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.1740 - accuracy: 0.9319 - val_loss: 0.2790 - val_accuracy: 0.8971\n",
            "Epoch 56/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.1735 - accuracy: 0.9315 - val_loss: 0.2803 - val_accuracy: 0.9027\n",
            "Epoch 57/60\n",
            "472/472 [==============================] - 7s 14ms/step - loss: 0.1783 - accuracy: 0.9302 - val_loss: 0.2633 - val_accuracy: 0.9051\n",
            "Epoch 58/60\n",
            "472/472 [==============================] - 7s 15ms/step - loss: 0.1708 - accuracy: 0.9307 - val_loss: 0.2688 - val_accuracy: 0.8998\n",
            "Epoch 59/60\n",
            "472/472 [==============================] - 7s 15ms/step - loss: 0.1754 - accuracy: 0.9319 - val_loss: 0.2590 - val_accuracy: 0.9064\n",
            "Epoch 60/60\n",
            "472/472 [==============================] - 7s 15ms/step - loss: 0.1672 - accuracy: 0.9343 - val_loss: 0.2857 - val_accuracy: 0.9023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NKr-tIU1HBP",
        "outputId": "3e8cec71-dce4-48ef-bfa0-95e98b2f593d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# base LSTM model - no convolutional layers \n",
        "model_base_lstm = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size+1, 100, weights=[embedding_matrix], trainable=False),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.LSTM(20, return_sequences=True),\n",
        "    tf.keras.layers.LSTM(20),\n",
        "    tf.keras.layers.Dropout(0.2),  \n",
        "    tf.keras.layers.Dense(256),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(128),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "print(model_base_lstm.summary())\n",
        "\n",
        "model_base_lstm.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "# important to note that default shuffle is set to true so the NN doesn't memorise a sequence and increases generability\n",
        "history = model_base_lstm.fit(X_train, y_train, epochs=200, batch_size=50, validation_data=(X_test, y_test), \n",
        "                              callbacks=tf.keras.callbacks.EarlyStopping(\n",
        "                                  monitor='val_loss', min_delta=0, patience=10, \n",
        "                                  verbose=0, mode='auto',baseline=None, \n",
        "                                  restore_best_weights=False\n",
        "                                  )\n",
        "                              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 100)         23440100  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, None, 100)         0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, None, 20)          9680      \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 20)                3280      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               5376      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 23,491,461\n",
            "Trainable params: 51,361\n",
            "Non-trainable params: 23,440,100\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "472/472 [==============================] - 20s 43ms/step - loss: 0.6525 - accuracy: 0.5926 - val_loss: 0.6656 - val_accuracy: 0.5856\n",
            "Epoch 2/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.6248 - accuracy: 0.6208 - val_loss: 0.6823 - val_accuracy: 0.6343\n",
            "Epoch 3/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.6149 - accuracy: 0.6343 - val_loss: 0.5820 - val_accuracy: 0.6584\n",
            "Epoch 4/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.5780 - accuracy: 0.6830 - val_loss: 0.5511 - val_accuracy: 0.7114\n",
            "Epoch 5/200\n",
            "472/472 [==============================] - 19s 41ms/step - loss: 0.6173 - accuracy: 0.6287 - val_loss: 0.5883 - val_accuracy: 0.6484\n",
            "Epoch 6/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.5662 - accuracy: 0.6591 - val_loss: 0.5534 - val_accuracy: 0.6767\n",
            "Epoch 7/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.5536 - accuracy: 0.6755 - val_loss: 0.5497 - val_accuracy: 0.6809\n",
            "Epoch 8/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.5432 - accuracy: 0.6870 - val_loss: 0.5425 - val_accuracy: 0.6855\n",
            "Epoch 9/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.5356 - accuracy: 0.6869 - val_loss: 0.5359 - val_accuracy: 0.6846\n",
            "Epoch 10/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.5220 - accuracy: 0.6996 - val_loss: 0.5071 - val_accuracy: 0.7577\n",
            "Epoch 11/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.4813 - accuracy: 0.7658 - val_loss: 0.4704 - val_accuracy: 0.7665\n",
            "Epoch 12/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.4787 - accuracy: 0.7691 - val_loss: 0.6947 - val_accuracy: 0.5237\n",
            "Epoch 13/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.6560 - accuracy: 0.5934 - val_loss: 0.5644 - val_accuracy: 0.6663\n",
            "Epoch 14/200\n",
            "472/472 [==============================] - 18s 39ms/step - loss: 0.5076 - accuracy: 0.7488 - val_loss: 0.5851 - val_accuracy: 0.6913\n",
            "Epoch 15/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.4637 - accuracy: 0.7945 - val_loss: 0.4408 - val_accuracy: 0.8137\n",
            "Epoch 16/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.5003 - accuracy: 0.7213 - val_loss: 0.4828 - val_accuracy: 0.7306\n",
            "Epoch 17/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.4619 - accuracy: 0.7719 - val_loss: 0.4297 - val_accuracy: 0.8281\n",
            "Epoch 18/200\n",
            "472/472 [==============================] - 19s 39ms/step - loss: 0.4375 - accuracy: 0.8127 - val_loss: 0.5312 - val_accuracy: 0.7106\n",
            "Epoch 19/200\n",
            "472/472 [==============================] - 19s 39ms/step - loss: 0.4619 - accuracy: 0.7831 - val_loss: 0.4374 - val_accuracy: 0.8179\n",
            "Epoch 20/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.4461 - accuracy: 0.8001 - val_loss: 0.4325 - val_accuracy: 0.8152\n",
            "Epoch 21/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.4334 - accuracy: 0.8075 - val_loss: 0.4291 - val_accuracy: 0.8040\n",
            "Epoch 22/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.4241 - accuracy: 0.8105 - val_loss: 0.4141 - val_accuracy: 0.8215\n",
            "Epoch 23/200\n",
            "472/472 [==============================] - 18s 39ms/step - loss: 0.3917 - accuracy: 0.8324 - val_loss: 0.3640 - val_accuracy: 0.8516\n",
            "Epoch 24/200\n",
            "472/472 [==============================] - 19s 39ms/step - loss: 0.5291 - accuracy: 0.7117 - val_loss: 0.4513 - val_accuracy: 0.7898\n",
            "Epoch 25/200\n",
            "472/472 [==============================] - 18s 39ms/step - loss: 0.4266 - accuracy: 0.8096 - val_loss: 0.3734 - val_accuracy: 0.8457\n",
            "Epoch 26/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.3760 - accuracy: 0.8429 - val_loss: 0.3458 - val_accuracy: 0.8630\n",
            "Epoch 27/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.3597 - accuracy: 0.8546 - val_loss: 0.3330 - val_accuracy: 0.8686\n",
            "Epoch 28/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.3438 - accuracy: 0.8610 - val_loss: 0.3287 - val_accuracy: 0.8717\n",
            "Epoch 29/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.3305 - accuracy: 0.8677 - val_loss: 0.3357 - val_accuracy: 0.8735\n",
            "Epoch 30/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.3247 - accuracy: 0.8715 - val_loss: 0.3176 - val_accuracy: 0.8749\n",
            "Epoch 31/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.3176 - accuracy: 0.8750 - val_loss: 0.3168 - val_accuracy: 0.8779\n",
            "Epoch 32/200\n",
            "472/472 [==============================] - 19s 39ms/step - loss: 0.3090 - accuracy: 0.8770 - val_loss: 0.3086 - val_accuracy: 0.8825\n",
            "Epoch 33/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.3036 - accuracy: 0.8806 - val_loss: 0.3059 - val_accuracy: 0.8825\n",
            "Epoch 34/200\n",
            "472/472 [==============================] - 19s 39ms/step - loss: 0.2937 - accuracy: 0.8840 - val_loss: 0.3031 - val_accuracy: 0.8852\n",
            "Epoch 35/200\n",
            "472/472 [==============================] - 19s 39ms/step - loss: 0.2888 - accuracy: 0.8850 - val_loss: 0.2982 - val_accuracy: 0.8896\n",
            "Epoch 36/200\n",
            "472/472 [==============================] - 19s 39ms/step - loss: 0.2863 - accuracy: 0.8877 - val_loss: 0.2854 - val_accuracy: 0.8891\n",
            "Epoch 37/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.2834 - accuracy: 0.8872 - val_loss: 0.3181 - val_accuracy: 0.8757\n",
            "Epoch 38/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.2793 - accuracy: 0.8907 - val_loss: 0.2871 - val_accuracy: 0.8922\n",
            "Epoch 39/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.2733 - accuracy: 0.8933 - val_loss: 0.2828 - val_accuracy: 0.8915\n",
            "Epoch 40/200\n",
            "472/472 [==============================] - 19s 41ms/step - loss: 0.2674 - accuracy: 0.8958 - val_loss: 0.2897 - val_accuracy: 0.8920\n",
            "Epoch 41/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.2694 - accuracy: 0.8940 - val_loss: 0.2873 - val_accuracy: 0.8934\n",
            "Epoch 42/200\n",
            "472/472 [==============================] - 19s 39ms/step - loss: 0.2598 - accuracy: 0.8982 - val_loss: 0.2881 - val_accuracy: 0.8932\n",
            "Epoch 43/200\n",
            "472/472 [==============================] - 19s 39ms/step - loss: 0.2618 - accuracy: 0.8975 - val_loss: 0.2813 - val_accuracy: 0.8934\n",
            "Epoch 44/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.2571 - accuracy: 0.8986 - val_loss: 0.2767 - val_accuracy: 0.8945\n",
            "Epoch 45/200\n",
            "472/472 [==============================] - 19s 39ms/step - loss: 0.2498 - accuracy: 0.9018 - val_loss: 0.2951 - val_accuracy: 0.8910\n",
            "Epoch 46/200\n",
            "472/472 [==============================] - 19s 39ms/step - loss: 0.2527 - accuracy: 0.9007 - val_loss: 0.2771 - val_accuracy: 0.8964\n",
            "Epoch 47/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.2549 - accuracy: 0.8998 - val_loss: 0.2814 - val_accuracy: 0.8964\n",
            "Epoch 48/200\n",
            "472/472 [==============================] - 19s 39ms/step - loss: 0.2463 - accuracy: 0.9017 - val_loss: 0.2769 - val_accuracy: 0.8959\n",
            "Epoch 49/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.2475 - accuracy: 0.9020 - val_loss: 0.2841 - val_accuracy: 0.8993\n",
            "Epoch 50/200\n",
            "472/472 [==============================] - 19s 39ms/step - loss: 0.2442 - accuracy: 0.9036 - val_loss: 0.2781 - val_accuracy: 0.8950\n",
            "Epoch 51/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.2402 - accuracy: 0.9042 - val_loss: 0.3251 - val_accuracy: 0.8789\n",
            "Epoch 52/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.2384 - accuracy: 0.9078 - val_loss: 0.2779 - val_accuracy: 0.8967\n",
            "Epoch 53/200\n",
            "472/472 [==============================] - 19s 39ms/step - loss: 0.2361 - accuracy: 0.9078 - val_loss: 0.2821 - val_accuracy: 0.8944\n",
            "Epoch 54/200\n",
            "472/472 [==============================] - 19s 40ms/step - loss: 0.2388 - accuracy: 0.9053 - val_loss: 0.2837 - val_accuracy: 0.8962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8YRNwmV39ry",
        "outputId": "590b8e32-c680-4773-ebdf-87da2be93034",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        }
      },
      "source": [
        "# getting average results for base lstm model\n",
        "\n",
        "results_base_mod = {}\n",
        "\n",
        "val_acc = []\n",
        "val_loss = []\n",
        "\n",
        "for i in range(5):\n",
        "    # base LSTM model - no convolutional layers \n",
        "    model_base_lstm = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size+1, 100, weights=[embedding_matrix], trainable=False),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        #tf.keras.layers.LSTM(20, return_sequences=True),\n",
        "        #tf.keras.layers.LSTM(20, return_sequences=True),\n",
        "        tf.keras.layers.LSTM(20, return_sequences=True),\n",
        "        tf.keras.layers.LSTM(20),\n",
        "        tf.keras.layers.Dropout(0.2),  \n",
        "        tf.keras.layers.Dense(256),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(128),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "    model_base_lstm.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "    # important to note that default shuffle is set to true so the NN doesn't memorise a sequence and increases generability\n",
        "    history = model_base_lstm.fit(X_train, y_train, epochs=30, batch_size=50, validation_data=(X_test, y_test))\n",
        "\n",
        "    m = max(history.history['val_accuracy'])\n",
        "\n",
        "    results_base_mod.append((history.history['val_accuracy'].index(m),m))\n",
        "\n",
        "print(\"Training Complete\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "472/472 [==============================] - 19s 41ms/step - loss: 0.6530 - accuracy: 0.5929 - val_loss: 0.6254 - val_accuracy: 0.6068\n",
            "Epoch 2/30\n",
            "472/472 [==============================] - 18s 39ms/step - loss: 0.6277 - accuracy: 0.6198 - val_loss: 0.6632 - val_accuracy: 0.5899\n",
            "Epoch 3/30\n",
            "211/472 [============>.................] - ETA: 9s - loss: 0.6369 - accuracy: 0.6208"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-8987c0c17260>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mmodel_base_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# important to note that default shuffle is set to true so the NN doesn't memorise a sequence and increases generability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_base_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ao0AMJrWCFb"
      },
      "source": [
        "# getting average results for best model\n",
        "\n",
        "results = {}\n",
        "\n",
        "val_acc = []\n",
        "val_loss = []\n",
        "\n",
        "for i in range(10):\n",
        "    model_lstm = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size+1, 100, weights=[embedding_matrix], trainable=False),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        # 1 x 5 filter for the convolutional layer as each sample is a vector\n",
        "        tf.keras.layers.Conv1D(32, 5, activation='relu',padding='same'),\n",
        "        tf.keras.layers.MaxPooling1D(pool_size=4),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Conv1D(64, 3, activation='relu',padding='same'),\n",
        "        tf.keras.layers.MaxPooling1D(pool_size=4),\n",
        "        tf.keras.layers.LSTM(20, return_sequences=True),\n",
        "        tf.keras.layers.LSTM(20, return_sequences=True),\n",
        "        tf.keras.layers.LSTM(20, return_sequences=True),\n",
        "        tf.keras.layers.LSTM(20),\n",
        "        tf.keras.layers.Dropout(0.2),  \n",
        "        tf.keras.layers.Dense(256),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(128),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model_lstm.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "    # important to note that default shuffle is set to true so the NN doesn't memorise a sequence and increases generability\n",
        "    history = model_lstm.fit(X_train, y_train, epochs=30, batch_size=50, validation_data=(X_test, y_test))\n",
        "\n",
        "    m = max(history.history['val_accuracy'])\n",
        "\n",
        "    results.append((history.history['val_accuracy'].index(m),m))\n",
        "\n",
        "print(\"Training Complete\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6t-vzKRQ62nh"
      },
      "source": [
        " # code modified from https://machinelearningmastery.com/how-to-calculate-precision-recall-f1-and-more-for-deep-learning-models/\n",
        "\n",
        "def calc_metrics(model,X_test,y_test):\n",
        "\n",
        "    # predict probabilities for test set\n",
        "    yhat_probs = model.predict(X_test, verbose=0)\n",
        "    # predict crisp classes for test set\n",
        "    yhat_classes = model.predict_classes(X_test, verbose=0)\n",
        "    yhat_probs = yhat_probs[:, 0]\n",
        "    yhat_classes = yhat_classes[:, 0]\n",
        "\n",
        "    # accuracy: (tp + tn) / (p + n)\n",
        "    accuracy = accuracy_score(y_test, yhat_classes)\n",
        "    print('Accuracy: %f' % accuracy)\n",
        "    # precision tp / (tp + fp)\n",
        "    precision = precision_score(y_test, yhat_classes)\n",
        "    print('Precision: %f' % precision)\n",
        "    # recall: tp / (tp + fn)\n",
        "    recall = recall_score(y_test, yhat_classes)\n",
        "    print('Recall: %f' % recall)\n",
        "    # f1: 2 tp / (2 tp + fp + fn)\n",
        "    f1 = f1_score(y_test, yhat_classes)\n",
        "    print('F1 score: %f' % f1)\n",
        "\n",
        "    return accuracy, precision, recall, f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWMnMlzx4iyK",
        "outputId": "9edc8345-fe89-4024-e804-dd79a0d8569a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "accuracy, precision, recall, f1 = calc_metrics(model_base_lstm,X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-8-8b1ad0af9df7>:8: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "Accuracy: 0.896236\n",
            "Precision: 0.896125\n",
            "Recall: 0.857932\n",
            "F1 score: 0.876613\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GhrkmIzXpAl",
        "outputId": "168474b5-93ae-4513-b786-6b29ce48e0b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "\n",
        "# Visualize the results:\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper right')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}